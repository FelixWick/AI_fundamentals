{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eefcc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/wick/language_models/.venv/lib/python3.13/site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/wick/language_models/.venv/lib/python3.13/site-packages (from gensim) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/wick/language_models/.venv/lib/python3.13/site-packages (from gensim) (1.16.2)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /Users/wick/language_models/.venv/lib/python3.13/site-packages (from gensim) (7.4.1)\n",
      "Requirement already satisfied: wrapt in /Users/wick/language_models/.venv/lib/python3.13/site-packages (from smart_open>=1.8.1->gensim) (1.17.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1bce4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3573c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load small pre-trained word embeddings (GloVe, 100-dimensional)\n",
    "model = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b06519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 100\n",
      "First 10 values: [-0.32307 -0.87616  0.21977  0.25268  0.22976  0.7388  -0.37954 -0.35307\n",
      " -0.84369 -1.1113 ]\n",
      "Cosine similarity between 'king' and 'queen': 0.751\n"
     ]
    }
   ],
   "source": [
    "# Example words\n",
    "word1 = \"king\"\n",
    "word2 = \"queen\"\n",
    "\n",
    "# Check if words exist in the vocabulary\n",
    "if word1 in model and word2 in model:\n",
    "    emb1 = model[word1]\n",
    "    emb2 = model[word2]\n",
    "    print(f\"Embedding length: {len(emb1)}\")\n",
    "    print(f\"First 10 values: {emb1[:10]}\")\n",
    "\n",
    "    # Cosine similarity\n",
    "    similarity = dot(emb1, emb2) / (norm(emb1) * norm(emb2))\n",
    "    print(f\"Cosine similarity between '{word1}' and '{word2}': {similarity:.3f}\")\n",
    "else:\n",
    "    print(\"One of the words is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3cb446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'man' and 'woman': 0.832\n"
     ]
    }
   ],
   "source": [
    "king_emb = emb1\n",
    "queen_emb = emb2\n",
    "man_emb = model[\"man\"]\n",
    "woman_emb = model[\"woman\"]\n",
    "\n",
    "similarity = dot(man_emb, woman_emb) / (norm(man_emb) * norm(woman_emb))\n",
    "print(f\"Cosine similarity between '{\"man\"}' and '{\"woman\"}': {similarity:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281be522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'king' and 'man': 0.512\n"
     ]
    }
   ],
   "source": [
    "similarity = dot(king_emb, man_emb) / (norm(king_emb) * norm(man_emb))\n",
    "print(f\"Cosine similarity between '{\"king\"}' and '{\"man\"}': {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b458b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'king' and 'woman': 0.366\n"
     ]
    }
   ],
   "source": [
    "similarity = dot(king_emb, woman_emb) / (norm(king_emb) * norm(woman_emb))\n",
    "print(f\"Cosine similarity between '{\"king\"}' and '{\"woman\"}': {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd667454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words similar to the analogy vector (king - man + woman):\n",
      "king: 0.855\n",
      "queen: 0.783\n",
      "monarch: 0.693\n",
      "throne: 0.683\n",
      "daughter: 0.681\n",
      "prince: 0.671\n",
      "princess: 0.664\n",
      "mother: 0.658\n",
      "elizabeth: 0.656\n",
      "father: 0.639\n"
     ]
    }
   ],
   "source": [
    "# Analogy: king - man + woman = queen\n",
    "analogy_vector = king_emb - man_emb + woman_emb\n",
    "# Find the most similar words to the analogy vector\n",
    "similar_words = model.similar_by_vector(analogy_vector, topn=10)\n",
    "print(\"Top 10 words similar to the analogy vector (king - man + woman):\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"{word}: {score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
